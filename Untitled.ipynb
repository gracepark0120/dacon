{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b74a90-ac2c-4e30-afd6-ad7eed5d80a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import kfp\n",
    "\n",
    "\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file) # 데이터 로드\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 1] #self.data의 idx번째 행의 1번 열에 위치한 이미지 경로\n",
    "        if './train_img' in img_path:\n",
    "          new_path = img_path.replace('./train_img', './data/train_img')\n",
    "        elif './test_img' in img_path:\n",
    "          new_path = img_path.replace('./test_img', './data/test_img')\n",
    "\n",
    "        image = cv2.imread(new_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # 이미지는 OpenCV를 사용하여 로드하고 RGB로 변환.\n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image # 추론 모드 시 이미지만 반환\n",
    "\n",
    "        mask_rle = self.data.iloc[idx, 2] # self.data의 idx번째 행의 2번 열에 위치한 RLE(Run-Length Encoding)로 인코딩된 마스크 정보를 가져옵니다.\n",
    "        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "        # 훈련 모드 시 rle 문자열로 인코딩된 마스크를 디코딩, 변환하여 이미지와 마스크를 반환.\n",
    "        # RLE로 인코딩된 마스크 정보를 디코딩하여 원래 형태의 마스크로 변환합니다. 변환된 마스크의 크기는 이미지의 높이와 너비와 동일합니다.\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "\n",
    "def _preprocess_data():\n",
    "    train_transform = A.Compose(\n",
    "            [\n",
    "                A.OneOf(\n",
    "                    [\n",
    "                        A.RandomBrightness(p=1),\n",
    "                        A.RandomBrightnessContrast(p=1),\n",
    "                        A.Emboss(p=1),\n",
    "                        A.RandomShadow(p=1),\n",
    "                        A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, fill_value=0, p=0.5),\n",
    "                        A.NoOp(),\n",
    "\n",
    "                    ],\n",
    "                    p=1,\n",
    "                ),\n",
    "                A.OneOf(\n",
    "                    [\n",
    "                        A.Blur(p=1),\n",
    "                        A.AdvancedBlur(p=1),\n",
    "                        A.MotionBlur(p=1),\n",
    "                    ],\n",
    "                    p=0.6,\n",
    "                ),\n",
    "                A.OneOf(\n",
    "                    [\n",
    "                        A.NoOp(),\n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.VerticalFlip(p=0.5),\n",
    "                        A.ShiftScaleRotate(p=0.5),\n",
    "                        A.Rotate(limit=90, p=1, border_mode=cv2.BORDER_REPLICATE),\n",
    "                        A.RandomRotate90(p=1)\n",
    "                    ],\n",
    "                    p=1,\n",
    "                ),\n",
    "                A.ElasticTransform(),\n",
    "                A.RandomCrop(224, 224),\n",
    "                A.Normalize(),\n",
    "                ToTensorV2(transpose_mask=True)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "    test_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(224, 224),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_dataset = SatelliteDataset(csv_file='./app/train.csv', transform=train_transform)\n",
    "    test_dataset = SatelliteDataset('./app/test.csv', transform=test_transform, infer=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=8)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Preprocessing data...')\n",
    "    _preprocess_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435c9b28-eed5-4b69-884d-5c2d6ac8a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97cba039-32ec-462d-8e4e-cb844b402338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33260ad8-9a69-4073-8e35-bf50035f77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class SMP(nn.Module):\n",
    "    def __init__(self, encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = smp.UnetPlusPlus(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=in_channels,\n",
    "            classes=classes,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76564c0-6b22-4a0a-b5bb-f728058212d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"model\": {\n",
    "        \"encoder_name\": \"timm-regnety_320\",\n",
    "        \"encoder_weights\": \"imagenet\",\n",
    "        \"in_channels\": 3,\n",
    "        \"classes\": 1\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"root\": \".\",\n",
    "        \"batch_size\": 64\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37663fc4-6d67-4081-9d8b-9a6f18e2e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1643d-1974-4fb5-9771-38610570d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SMP(\n",
    "            encoder_name=configs[\"model\"][\"encoder_name\"],\n",
    "            encoder_weights=configs[\"model\"][\"encoder_weights\"],\n",
    "            in_channels=configs[\"model\"][\"in_channels\"],\n",
    "            classes=configs[\"model\"][\"classes\"],\n",
    "        )\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba70a45-58b0-445c-acc7-7d63491c629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# 모델 초기화\n",
    "# GPU를 사용할 경우\n",
    "\n",
    "def train_model(train_dataloader, model, device, epoch_num, name):\n",
    "    logs = []\n",
    "    # loss function과 optimizer 정의\n",
    "    #criterion = HybridLoss()\n",
    "    #criterion = DiceLoss()\n",
    "    criterion = torch.nn.BCEWithLogitsLoss() # 이진 교차 엔트로피\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    for epoch in range(epoch_num):  # 10 에폭 동안 학습합니다.\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for images, masks in tqdm(train_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(images)\n",
    "\n",
    "            loss = criterion(out, masks.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(train_dataloader)}')\n",
    "        \n",
    "        log_epoch = {'epoch': epoch+1,'train_loss': epoch_loss}\n",
    "        logs.append(log_epoch)\n",
    "        scheduler.step(epoch_loss)  # 학습률 스케쥴러 호출\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            torch.save(model.state_dict(), './app/train_result/' + name + '_' + str(epoch+1) + '.pth')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_dataset')\n",
    "    parser.add_argument('--device')\n",
    "    parser.add_argument('--model')\n",
    "    parser.add_argument('--epoch_num')\n",
    "    parser.add_argument('--name') # 가중치 파일 이름\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    train_model(args.train_dataset, args.device, args.model, args.epoch_num, args.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0ce783-20af-4cdf-b5fd-38c94b2e8107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfp                      1.6.3\n",
      "kfp-pipeline-spec        0.1.16\n",
      "kfp-server-api           1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "094b3232-58d2-44d6-b747-6adce2019ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.8/site-packages (from albumentations) (1.22.4)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from albumentations) (5.4.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.8/site-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from albumentations) (1.7.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (4.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (0.24.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.8.6)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (3.4.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2022.8.12)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.21.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.16.0)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.1 opencv-python-headless-4.8.0.76 qudida-0.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe2357-1cb0-4524-9489-659d51fe72ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
