import kfp
from kfp import dsl
from kfp.components import create_component_from_func, InputPath, OutputPath, func_to_container_op
from kfp.dsl.types import List
from functools import partial


# Define a component to train the model


def train_model(configs:dict, num_epoch: int=1)-> str :
    import subprocess
    subprocess.run(["pip3", "uninstall", "torch", "torchvision", "torchaudio", "--yes"])
    subprocess.run(["apt-get", "update"])
    subprocess.run(["pip3", "install", "torch", "torchvision", "torchaudio", "--index-url", "https://download.pytorch.org/whl/cu118"])
    
    import torch
    from minio import Minio
    import pandas as pd
    import albumentations as A
    from albumentations.pytorch import ToTensorV2
    from torch.utils.data import Dataset, DataLoader
    import numpy as np
    import cv2
    import torch
    import argparse
    from tqdm import tqdm
    import segmentation_models_pytorch as smp
    
    def rle_decode(mask_rle, shape):
        s = mask_rle.split()
        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
        starts -= 1
        ends = starts + lengths
        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
        for lo, hi in zip(starts, ends):
            img[lo:hi] = 1
        return img.reshape(shape)

    class SatelliteDataset(Dataset):
        def __init__(self, csv_file, transform=None, infer=False):
            self.data = pd.read_csv(csv_file) 
            self.transform = transform
            self.infer = infer

        def __len__(self):
            return len(self.data)

        def __getitem__(self, idx):
            img_path = self.data.iloc[idx, 1] 
            image = cv2.imread(img_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            if self.infer:
                if self.transform:
                    image = self.transform(image=image)['image']
                return image 

            mask_rle = self.data.iloc[idx, 2] 
            mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))
            if self.transform:
                augmented = self.transform(image=image, mask=mask)
                image = augmented['image']
                mask = augmented['mask']

            return image, mask

    train_transform = A.Compose(
            [
                A.OneOf(
                    [
                        A.RandomBrightness(p=1),
                        A.RandomBrightnessContrast(p=1),
                        A.Emboss(p=1),
                        A.RandomShadow(p=1),
                        A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, fill_value=0, p=0.5),
                        A.NoOp(),

                    ],
                    p=1,
                ),
                A.OneOf(
                    [
                        A.Blur(p=1),
                        A.MotionBlur(p=1),
                    ],
                    p=0.6,
                ),
                A.OneOf(
                    [
                        A.NoOp(),
                        A.HorizontalFlip(p=0.5),
                        A.VerticalFlip(p=0.5),
                        A.ShiftScaleRotate(p=0.5),
                        A.Rotate(limit=90, p=1, border_mode=cv2.BORDER_REPLICATE),
                        A.RandomRotate90(p=1)
                    ],
                    p=1,
                ),
                A.ElasticTransform(),
                A.RandomCrop(224, 224),
                A.Normalize(),
                ToTensorV2(transpose_mask=True)
            ]
        )
    model_name = configs["model"]
    encoder_name = configs["encoder_name"]
    encoder_weights = configs["encoder_weights"]
    minio_object_name = configs["base_path"]
    
    train_dataset = SatelliteDataset(csv_file='./train.csv', transform=train_transform)
    train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=6)

    minio_client = Minio(
        "35.190.217.122:9000",
        access_key="minio",
        secret_key="minio123",
        secure=False
    )
    minio_bucket = "mlpipeline"
    
    minio_client.fget_object(minio_bucket, 'data/'+minio_object_name, "base_model.pth")
    print("minio download")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(device)
    if model_name == "unetplusplus":
        model = smp.UnetPlusPlus(
        encoder_name=encoder_name,
        encoder_weights=encoder_weights,
        in_channels=3,
        classes=1,
        )
    else:
        model = smp.DeepLabV3Plus(
        encoder_name=encoder_name,
        encoder_weights=encoder_weights,
        in_channels=3,
        classes=1,
        ) 
    
    model = model.to(device)
    weight_init = torch.load("base_model.pth")
    model.load_state_dict(weight_init, strict=False)
    print("--------------------------------------------------")
    
    
    logs = []

    #criterion = HybridLoss()
    #criterion = DiceLoss()
    criterion = torch.nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)

    torch.autograd.set_detect_anomaly(True)

    for epoch in range(num_epoch):
        model.train()
        epoch_loss = 0

        for images, masks in tqdm(train_dataloader):
            images = images.float().to(device)
            masks = masks.float().to(device)

            optimizer.zero_grad()
            out = model(images)

            loss = criterion(out, masks.unsqueeze(1))

            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

        print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(train_dataloader)}')

        log_epoch = {'epoch': epoch+1,'train_loss': epoch_loss}
        logs.append(log_epoch)
        scheduler.step(epoch_loss)  
    
    output_model_path = encoder_name+"_"+encoder_weights
    print(output_model_path)
    torch.save(model.state_dict(), output_model_path+'.pth')
    torch.save(model, output_model_path+'.pt')
    minio_client.fput_object(minio_bucket, 'data/'+output_model_path+'.pth', output_model_path+'.pth')
    minio_client.fput_object(minio_bucket, 'model/'+output_model_path+'.pt', output_model_path+'.pt')
    
    return output_model_path


def test_model(base_path: str) -> str:
  #  import subprocess
  #  subprocess.run(["pip3", "uninstall", "torch", "torchvision", "torchaudio", "--yes"])
  #  subprocess.run(["apt-get", "update"])
  # subprocess.run(["pip3", "install", "torch", "torchvision", "torchaudio", "--index-url", "https://download.pytorch.org/whl/cu118"])
    
    import torch
    pytorch_version = torch.__version__
    print(f"cuda_available: {torch.cuda.get_arch_list()}")
    print(f"cuda_device : {torch.version.cuda}")
    print(f"cuda_device_name: {current_cuda_device_name}")
    print(f"PyTorch: {pytorch_version}")
    from minio import Minio
    import pandas as pd
    import albumentations as A
    from albumentations.pytorch import ToTensorV2
    from torch.utils.data import Dataset, DataLoader
    import numpy as np
    import cv2
    import torch
    import argparse
    from tqdm import tqdm
    import segmentation_models_pytorch as smp
    from typing import List, Union
    from joblib import Parallel, delayed
    minio_client = Minio(
        "35.190.217.122:9000",
        access_key="minio",
        secret_key="minio123",
        secure=False
    )
    minio_bucket = "mlpipeline"
    
    minio_client.fget_object(minio_bucket, "data/"+base_path, "base_model.pth")
    encoder_name, encoder_weights = base_path.rstrip('.pth').rsplit('_', 1)
    minio_client.fget_object(minio_bucket, "data/test2.csv", "test2.csv")

    print("minio download")
    
    test_transform = A.Compose(
        [
            A.Resize(224, 224),
            A.Normalize(),
            ToTensorV2()
        ]
    )
    # RLE decoding function
    def rle_decode(mask_rle, shape):
        s = mask_rle.split()
        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
        starts -= 1
        ends = starts + lengths
        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
        for lo, hi in zip(starts, ends):
            img[lo:hi] = 1
        return img.reshape(shape)
    
    # RLE encoding function
    def rle_encode(mask):
        pixels = mask.flatten()
        pixels = np.concatenate([[0], pixels, [0]])
        runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
        runs[1::2] -= runs[::2]
        return ' '.join(str(x) for x in runs)
    
    def dice_score(prediction: np.array, ground_truth: np.array, smooth=1e-7) -> float:
        '''
        Calculate Dice Score between two binary masks.
        '''
        intersection = np.sum(prediction * ground_truth)
        return (2.0 * intersection + smooth) / (np.sum(prediction) + np.sum(ground_truth) + smooth)
    
    class SatelliteDataset(Dataset):
        def __init__(self, csv_file, transform=None, infer=False):
            self.data = pd.read_csv(csv_file) 
            self.transform = transform
            self.infer = infer

        def __len__(self):
            return len(self.data)

        def __getitem__(self, idx):
            img_path = self.data.iloc[idx, 1] 
            image = cv2.imread(img_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            if self.infer:
                if self.transform:
                    image = self.transform(image=image)['image']
                return image 

            mask_rle = self.data.iloc[idx, 2] 
            mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))
            if self.transform:
                augmented = self.transform(image=image, mask=mask)
                image = augmented['image']
                mask = augmented['mask']

            return image, mask
        
    def calculate_dice_scores(ground_truth_df, prediction_df, img_shape=(224, 224)) -> List[float]:
        # Keep only the rows in the prediction dataframe that have matching img_ids in the ground truth dataframe
        prediction_df = prediction_df[prediction_df.iloc[:, 0].isin(ground_truth_df.iloc[:, 0])]
        prediction_df.index = range(prediction_df.shape[0])

        # Extract the mask_rle columns
        pred_mask_rle = prediction_df.iloc[:, 2]
        gt_mask_rle = ground_truth_df.iloc[:, 2]

        def calculate_dice(pred_rle, gt_rle):
            pred_mask = rle_decode(pred_rle, img_shape)
            gt_mask = rle_decode(gt_rle, img_shape)

            if np.sum(gt_mask) > 0 or np.sum(pred_mask) > 0:
                return dice_score(pred_mask, gt_mask)
            else:
                return None  # No valid masks found, return None

        dice_scores = Parallel(n_jobs=-1)(
            delayed(calculate_dice)(pred_rle, gt_rle) for pred_rle, gt_rle in zip(pred_mask_rle, gt_mask_rle)
        )
        dice_scores = [score for score in dice_scores if score is not None]  # Exclude None values
        return np.mean(dice_scores)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = smp.UnetPlusPlus(
        encoder_name=encoder_name,
        encoder_weights=encoder_weights,
        in_channels=3,
        classes=1,
        )
        
    
    model = model.to(device)
    model.load_state_dict(torch.load("base_model.pth"))
    print("--------------------------------------------------")
    print(device)
    test_dataset = SatelliteDataset('test2.csv', transform=test_transform, infer=True)
    # test2 : 20% of train dataset
    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)

    with torch.no_grad():
        model.eval()
        result = []
        for images in tqdm(test_dataloader):
            images = images.to(device)

            outputs = model(images)
            masks = torch.sigmoid(outputs).cpu().numpy()
            #masks = np.squeeze(masks, axis=1)
            masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35

            for i in range(len(images)):
                mask_rle = rle_encode(masks[i])
                if mask_rle == '': # no pixel -1
                    result.append(-1)
                else:
                    result.append(mask_rle)
    
    # making submission file
    #submit = pd.read_csv('/sample_submission.csv')
    #submit['mask_rle'] = result
    #submit.to_csv('/sch_new_paper2_50.csv', index=False)

    image_names = [img_name for img_name in test_dataset.data.iloc[:, 0]]
    result_df = pd.DataFrame(image_names, columns=["image_id"])

    # add image path(image_name.png format)
    result_df['image_path'] = result_df['image_id'].apply(lambda x: './train_img2/' + x + '.png')
    result_df['mask_rle'] = result
    train = pd.read_csv("test2.csv")
    dice_score = calculate_dice_scores(train, result_df)
    file_name = encoder_name+'_'+encoder_weights+'.txt'
    with open(file_name, 'w') as file:
        file.write(dice_score)
    
    minio_client.fput_object(minio_bucket, "data/"+file_name, file_name)

    return str(dice_score)


def compare_result():
    #  encoder, weight, dicescore 
    import pandas as pd

    def create_dice_score_table(encoder_names, encoder_weights, dice_scores):
        data = {
            'Encoder Name': encoder_names,
            'Encoder Weight': encoder_weights,
            'Dice Score': dice_scores
        }
        df = pd.DataFrame(data)
        return df
    
    # Sample usage:
    encoder_names = ['resnet50', 'densenet121']
    encoder_weights = ['imagenet', 'imagenet']
    dice_scores = [0.85, 0.92]

    # visualization 
    result_df = create_dice_score_table(encoder_names, encoder_weights, dice_scores)
    print(result_df)
   
    
    return 
    


def model_serving(best_model: str):
    from kubernetes import client 
    from kserve import KServeClient
    from kserve import constants
    from kserve import utils
    from kserve import V1beta1InferenceService
    from kserve import V1beta1InferenceServiceSpec
    from kserve import V1beta1PredictorSpec
    from kserve import V1beta1TorchServeSpec
    from datetime import datetime
    import torch
    from torch.autograd import Variable

    namespace = utils.get_default_target_namespace()
    now = datetime.now()
    v = now.strftime("%Y-%m-%d--%H-%M-%S")

    name='satellite_segmentation-{}'.format(v)
    kserve_version='v1beta1'
    api_version = constants.KSERVE_GROUP + '/' + kserve_version
  
    # Load your trained Unet++ model
    model = YourPyTorchUnetPlusPlusModel() 
    model.eval()

    # Define the version of your model
    model_version = datetime.now().strftime("%Y%m%d%H%M%S")

    # Export the model in TorchServe format
    export_path = f'/models/unetplusplus/{model_version}'
    torch.jit.save(torch.jit.script(model), export_path)

    # Create a KServe InferenceService
    isvc = V1beta1InferenceService(
        api_version=api_version,
        kind=constants.KSERVE_KIND,
        metadata=client.V1ObjectMeta(name=name, namespace=namespace),
        spec=V1beta1InferenceServiceSpec(
        predictor=V1beta1PredictorSpec(
            service_account_name="sa-minio-kserve",
            pytorch=(V1beta1TorchServeSpec(
                storage_uri='s3://mlpipeline/models/{export_path}'))
            )
        )
    )

    ks_client = KServeClient()
    ks_client.create(isvc)


        
@dsl.pipeline(
    name="Satellite Image Pipeline",
    description="Pipeline for satellite image processing",
)
def satellite_image_pipeline():

    train_op = create_component_from_func(train_model, packages_to_install=["requests_toolbelt", "urllib3", "minio"],base_image="gracehpark/dacon_4:v1")
    test_op = create_component_from_func(test_model, packages_to_install=["requests_toolbelt", "urllib3", "minio"],base_image="gracehpark/dacon_4:v1")
    #compare_op = create_component_from_func(compare_result, packages_to_install=["matplotlib"], base_image="gracehpark/dacon_3:v1")
    #serving_op = create_component_from_func(model_serving, packages_to_install=['kserve==0.8.0.1'], base_image="")
    configs1 = {
        "model":"unetplusplus",
        "encoder_name":"timm-regnety_320",
        "encoder_weights":"imagenet",
        "base_path":"sc_paper2_30.pth"
    }
    configs2 = {
        "model":"unetplusplus",
        "encoder_name":"resnet152",
        "encoder_weights":"imagenet",
        "base_path":"new_paper2_152_40.pth"
    }
    configs3 = {
       "model":"deeplabv3plus",
        "encoder_name": "resnet152",
        "encoder_weights": "imagenet",
        "base_path" : "v3plus1_30.pth"
    }
    step1 = train_op(configs=configs1, num_epoch=1).set_gpu_limit(1).set_memory_limit("15G").set_display_name("train:unet++/resnet152/imagenet")
    step2 = test_op(base_path=step1.output)
    step3 = train_op(configs=configs2, num_epoch=1).set_gpu_limit(1).set_memory_limit("15G").set_display_name("train:unet++/resnet152/imagenet")
    step4 = test_op(base_path=step3.output)
    step5 = train_op(configs=configs3, num_epoch=1).set_gpu_limit(1).set_memory_limit("15G").set_display_name("train:deeplabv3plus/resnet152/imagenet")
    step6 = test_op(base_path=step5.output)
    
    #step7 = compare_op().after(step6)
    step3.after(step2)
    step5.after(step4)

    #step6 = serving_op(best_model=step5.output)


if __name__ == "__main__":
    import kfp
    from kfp.compiler import Compiler

    Compiler().compile(satellite_image_pipeline, "pipeline.yaml")

    """client = kfp.Client()
    client.create_run_from_pipeline_func(
            satellite_image_pipeline,
            arguments={
                "num_epoch": "practice1.pth",  # Example arguments
            },
            image=image_uri,
        )"""
