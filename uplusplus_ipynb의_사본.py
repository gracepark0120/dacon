# -*- coding: utf-8 -*-
"""uplusplus.ipynb의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iZ2qTv-_W1nMLw16B7R_bAeWsytMSp7j
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive')
# %cd "/content/gdrive/MyDrive"

folder1_path = '/content/gdrive/MyDrive'
folder2_path = '/content/gdrive/MyDrive/train_img'
folder3_path = '/content/gdrive/Othercomputers/내 노트북/test_img'

!pip install segmentation_models_pytorch --quiet

import segmentation_models_pytorch as smp

"""## Utils

"""

# RLE 디코딩 함수
def rle_decode(mask_rle, shape):
    s = mask_rle.split()
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = 1
    return img.reshape(shape)

# RLE 인코딩 함수
def rle_encode(mask):
    pixels = mask.flatten()
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)

"""## example"""

import cv2
import numpy as np
import pandas as pd
from google.colab.patches import cv2_imshow
df = pd.read_csv("./train.csv")

image_path = df.iloc[1,1] # Replace with the path to the image file
image = cv2.imread(image_path)

cv2_imshow(image)
# Example mask_rle (Replace with the actual mask_rle for TRAIN_0000)
mask_rle = df.iloc[1,2]

# Convert mask_rle to binary mask image
binary_mask_image = rle_decode(mask_rle, shape=(1024, 1024))

# Convert binary_mask_image to grayscale
gray_mask_image = binary_mask_image * 255

# Find contours in the binary mask image
contours, _ = cv2.findContours(binary_mask_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# Draw each contour as a line on the original image
for contour in contours:
    cv2.drawContours(image, [contour], -1, (0, 0, 255), 1)  # Red color for the contours

# Display the grayscale mask image using cv2_imshow
cv2_imshow(gray_mask_image)

"""## Train Model

#### Dataset
"""

import numpy as np
import torch
import torch.nn as nn
from typing import List
import torch.nn.functional as F
import sys, os
import os.path as osp
#sys.path.append(osp.dirname(osp.dirname(__file__)))

import os
import cv2
import pandas as pd
import numpy as np

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

from tqdm import tqdm
import albumentations as A
from albumentations.pytorch import ToTensorV2

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class SatelliteDataset(Dataset):
    def __init__(self, csv_file, transform=None, infer=False):
        self.data = pd.read_csv(csv_file) # 데이터 로드
        self.transform = transform
        self.infer = infer

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path = self.data.iloc[idx, 1] #self.data의 idx번째 행의 1번 열에 위치한 이미지 경로
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        # 이미지는 OpenCV를 사용하여 로드하고 RGB로 변환.
        if self.infer:
            if self.transform:
                image = self.transform(image=image)['image']
            return image # 추론 모드 시 이미지만 반환

        mask_rle = self.data.iloc[idx, 2] # self.data의 idx번째 행의 2번 열에 위치한 RLE(Run-Length Encoding)로 인코딩된 마스크 정보를 가져옵니다.
        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))
        # 훈련 모드 시 rle 문자열로 인코딩된 마스크를 디코딩, 변환하여 이미지와 마스크를 반환.
        # RLE로 인코딩된 마스크 정보를 디코딩하여 원래 형태의 마스크로 변환합니다. 변환된 마스크의 크기는 이미지의 높이와 너비와 동일합니다.
        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']

        return image, mask

"""OpenCV (cv2)를 사용하여 이미지를 처리합니다.
이미지를 RGB 색 공간으로 변환합니다.
마스크 정보는 RLE (Run-Length Encoding)로 인코딩되어 있으며, 이를 디코딩하여 마스크를 생성합니다.
이미지와 마스크에 대한 데이터 변환을 수행할 수 있습니다.
파일 경로를 변경하여 이미지를 로드합니다.

## data for validation
"""

from sklearn.model_selection import train_test_split

df = pd.read_csv("./train.csv")
train_df, val_df = train_test_split(df, test_size=0.2, random_state=0, shuffle=True)
val_df.to_csv('val2.csv',index=False)

df = pd.read_csv('./train.csv')
df

df = pd.read_csv('./val2.csv')
df

"""## 전처리"""

train_transform = A.Compose(
            [
                A.OneOf(
                    [
                        A.RandomBrightness(p=1),
                        A.RandomBrightnessContrast(p=1),
                        A.Emboss(p=1),
                        A.RandomShadow(p=1),
                        A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, fill_value=0, p=0.5),
                        A.NoOp(),

                    ],
                    p=1,
                ),
                A.OneOf(
                    [
                        A.Blur(p=1),
                        A.AdvancedBlur(p=1),
                        A.MotionBlur(p=1),
                    ],
                    p=0.6,
                ),
                A.OneOf(
                    [
                        A.NoOp(),
                        A.HorizontalFlip(p=0.5),
                        A.VerticalFlip(p=0.5),
                        A.ShiftScaleRotate(p=0.5),
                        A.Rotate(limit=90, p=1, border_mode=cv2.BORDER_REPLICATE),
                        A.RandomRotate90(p=1)
                    ],
                    p=1,
                ),
                A.ElasticTransform(),
                A.RandomCrop(224, 224),
                A.Normalize(),
                ToTensorV2(transpose_mask=True)
            ]
        )


test_transform = A.Compose(
    [
        A.Resize(224, 224),
        A.Normalize(),
        ToTensorV2()
    ]
)

dataset = SatelliteDataset(csv_file='./train.csv', transform=train_transform)
dataloader = DataLoader(dataset, batch_size=20, shuffle=True, num_workers=2)

"""## Model"""

class SMP(nn.Module):
    def __init__(self, encoder_name="resnet34", encoder_weights="imagenet", in_channels=3, classes=1):
        super().__init__()

        self.model = smp.UnetPlusPlus(
            encoder_name=encoder_name,
            encoder_weights=encoder_weights,
            in_channels=in_channels,
            classes=classes,
        )

    def forward(self, x):
        x = self.model(x)
        return x

configs = {
    "model": {
        "encoder_name": "resnet152",
        "encoder_weights": "imagenet",
        "in_channels": 3,
        "classes": 1
    },
    "data": {
        "root": ".",
        "batch_size": 64
    },
}

model = SMP(
            encoder_name=configs["model"]["encoder_name"],
            encoder_weights=configs["model"]["encoder_weights"],
            in_channels=configs["model"]["in_channels"],
            classes=configs["model"]["classes"],
        )
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

model = smp.DeepLabV3Plus( encoder_name="resnet152", encoder_weights="imagenet", activation= 'sigmoid', encoder_output_stride = 16, decoder_atrous_rates = (4, 8, 16), in_channels=3, classes=2)

"""## 가중치 로드

"""

weight_file_path = './unet3_ag/new_paper2_152_40.pth'
model.load_state_dict(torch.load(weight_file_path))

"""## 모델 저장"""

torch.save(model, './unet3_ag/deeplabv3plus_resnet152_imagenet.pt')

"""## 모델 로드"""

# 모델 로드 경로 설정
model_load_path = '/content/gdrive/MyDrive/unet3_ag/unetplusplus_resnet152_imagenet.pt'

# 모델 로드
model = torch.load(model_load_path)

# 모델을 평가 모드로 설정 (옵션)
model.eval()

"""## Training"""

# 모델 초기화
# GPU를 사용할 경우

logs = []
# loss function과 optimizer 정의
#criterion = HybridLoss()
#criterion = DiceLoss()
criterion = torch.nn.BCEWithLogitsLoss() # 이진 교차 엔트로피
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)

torch.autograd.set_detect_anomaly(True)

for epoch in range(2):  # 10 에폭 동안 학습합니다.
    model.train()
    epoch_loss = 0

    for images, masks in tqdm(dataloader):
        images = images.float().to(device)
        masks = masks.float().to(device)

        optimizer.zero_grad()
        out = model(images)

        loss = criterion(out, masks.unsqueeze(1))

        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

    print(f'Epoch {9+epoch+1}, Loss: {epoch_loss/len(dataloader)}')
    log_epoch = {'epoch': epoch+1,'train_loss': epoch_loss}
    logs.append(log_epoch)
    scheduler.step(epoch_loss)  # 학습률 스케쥴러 호출

    if (9+epoch+1) % 5 == 0:
        torch.save(model.state_dict(), '/unet3_ag/try' + str(9+epoch+1) + '.pth')

"""## validation"""

#model = smp.UnetPlusPlus(encoder_name="resnet34", encoder_weights="imagenet", in_channels=3, classes=1)

#model = smp.DeepLabV3Plus( encoder_name="resnet152", encoder_weights="imagenet", activation= 'sigmoid', encoder_output_stride = 16, decoder_atrous_rates = (4, 8, 16), in_channels=3, classes=2)
test_dataset = SatelliteDataset(csv_file='./val2.csv', transform=test_transform, infer=True)
test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=2)

with torch.no_grad():
    model.eval()
    result = []
    for images in tqdm(test_dataloader):
        images = images.to(device)

        outputs = model(images)
        masks = torch.sigmoid(outputs).cpu().numpy()
        #masks = np.squeeze(masks, axis=1)
        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35

        for i in range(len(images)):
            mask_rle = rle_encode(masks[i])
            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1
                result.append(-1)
            else:
                result.append(mask_rle)

import pandas as pd

# 이미지 이름 추출
image_names = [img_name for img_name in test_dataset.data.iloc[:, 0]]
result_df = pd.DataFrame(image_names, columns=["image_id"])


# 이미지 경로 추가 (image_name.png 형식)
result_df['image_path'] = result_df['image_id'].apply(lambda x: './train_img2/' + x + '.png')


result_df['mask_rle'] = result

result_df

result_df

"""## dice score"""

import numpy as np
import pandas as pd
from typing import List, Union
from joblib import Parallel, delayed


def rle_decode(mask_rle: Union[str, int], shape=(224, 224)) -> np.array:
    '''
    mask_rle: run-length as string formatted (start length)
    shape: (height,width) of array to return
    Returns numpy array, 1 - mask, 0 - background
    '''
    if mask_rle == -1:
        return np.zeros(shape)

    s = mask_rle.split()
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = 1
    return img.reshape(shape)


def dice_score(prediction: np.array, ground_truth: np.array, smooth=1e-7) -> float:
    '''
    Calculate Dice Score between two binary masks.
    '''
    intersection = np.sum(prediction * ground_truth)
    return (2.0 * intersection + smooth) / (np.sum(prediction) + np.sum(ground_truth) + smooth)


def calculate_dice_scores(ground_truth_df, prediction_df, img_shape=(224, 224)) -> List[float]:
    '''
    Calculate Dice scores for a dataset.
    '''


    # Keep only the rows in the prediction dataframe that have matching img_ids in the ground truth dataframe
    prediction_df = prediction_df[prediction_df.iloc[:, 0].isin(ground_truth_df.iloc[:, 0])]
    # ground_truth = train , prediction = result(train 데이터셋으로 테스트한거임.)
    prediction_df.index = range(prediction_df.shape[0])

    # Extract the mask_rle columns
    pred_mask_rle = prediction_df.iloc[:, 2]
    gt_mask_rle = ground_truth_df.iloc[:, 2]


    def calculate_dice(pred_rle, gt_rle):
        pred_mask = rle_decode(pred_rle, img_shape)
        gt_mask = rle_decode(gt_rle, img_shape)


        if np.sum(gt_mask) > 0 or np.sum(pred_mask) > 0:
            return dice_score(pred_mask, gt_mask)
        else:
            return None  # No valid masks found, return None


    dice_scores = Parallel(n_jobs=-1)(
        delayed(calculate_dice)(pred_rle, gt_rle) for pred_rle, gt_rle in zip(pred_mask_rle, gt_mask_rle)
    )


    dice_scores = [score for score in dice_scores if score is not None]  # Exclude None values


    return np.mean(dice_scores)

train = pd.read_csv("./val2.csv")
calculate_dice_scores(train, result_df)
# 0.67

# RLE 인코딩 함수
def rle_encode(mask):
    pixels = mask.flatten()
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)

test_dataset = SatelliteDataset('/content/gdrive/MyDrive/test.csv', transform=test_transform, infer=True)
test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)

with torch.no_grad():
    model.eval()
    result = []
    for images in tqdm(test_dataloader):
        images = images.float().to(device)

        outputs = model(images)
        masks = torch.sigmoid(outputs).cpu().numpy()
        masks = np.squeeze(masks, axis=1)
        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35

        for i in range(len(images)):
            mask_rle = rle_encode(masks[i])
            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1
                result.append(-1)
            else:
                result.append(mask_rle)

submit = pd.read_csv(folder2_path+'/sample_submission.csv')
submit['mask_rle'] = result
submit.to_csv(folder2_path+'/sch_new_paper2_50.csv', index=False)
